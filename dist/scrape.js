import "./loadEnv.js";
import path from "path";
// Debug environment variables and paths
console.log("Current working directory:", process.cwd());
console.log("Resolved .env path:", path.resolve(process.cwd(), ".env"));
console.log("Environment variables loaded:");
console.log("DATABASE_URL:", process.env.DATABASE_URL ? "Set" : "Not set");
console.log("ORGANIZATION_NAME:", process.env.ORGANIZATION_NAME ? "Set" : "Not set");
import { chromium } from "playwright";
import fs from "fs";
import readline from "readline";
import { saveScrapedJobs, checkJobExists } from "./lib/db.js";
// Config for storing user credentials
const CONFIG_DIR = process.cwd() + "/.config";
const CREDENTIALS_FILE = CONFIG_DIR + "/credentials.json";
// Ensure config directory exists
if (!fs.existsSync(CONFIG_DIR)) {
    fs.mkdirSync(CONFIG_DIR, { recursive: true });
}
// Function to read user input
async function promptUser(question) {
    const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout,
    });
    return new Promise((resolve) => {
        rl.question(question, (answer) => {
            rl.close();
            resolve(answer);
        });
    });
}
// Function to clean customer names by removing extra content
function cleanCustomerName(rawName) {
    if (!rawName)
        return "";
    console.log(`üßπ Cleaning customer name: "${rawName}"`);
    // With the new extraction method, customer names should be much cleaner
    // So we'll do minimal cleanup
    let cleaned = rawName
        .replace(/\s+/g, " ") // Normalize whitespace
        .trim();
    // Remove any remaining problematic characters that might have slipped through
    cleaned = cleaned
        .replace(/[^\w\s&.,'-]/g, " ") // Remove special chars except common business ones
        .replace(/\s+/g, " ") // Normalize whitespace again
        .trim();
    // Database length constraint
    const MAX_CUSTOMER_NAME_LENGTH = 100;
    if (cleaned.length > MAX_CUSTOMER_NAME_LENGTH) {
        console.warn(`Customer name too long (${cleaned.length} chars), truncating: "${cleaned}"`);
        cleaned = cleaned.substring(0, MAX_CUSTOMER_NAME_LENGTH).trim();
    }
    // Validate result
    if (cleaned.length < 2) {
        console.warn(`Customer name too short after cleaning: "${rawName}" -> "${cleaned}"`);
        // Emergency fallback
        if (cleaned.length === 0) {
            cleaned = "Unknown Customer";
        }
    }
    console.log(`‚úÖ Customer name result: "${cleaned}"`);
    return cleaned;
}
// Function to load saved credentials
async function loadCredentials() {
    try {
        if (fs.existsSync(CREDENTIALS_FILE)) {
            const data = fs.readFileSync(CREDENTIALS_FILE, "utf8");
            return JSON.parse(data);
        }
    }
    catch (error) {
        console.error("Error loading credentials:", error);
    }
    return { accounts: [] };
}
// Function to save credentials
async function saveCredentials(credentials) {
    try {
        fs.writeFileSync(CREDENTIALS_FILE, JSON.stringify(credentials, null, 2), "utf8");
    }
    catch (error) {
        console.error("Error saving credentials:", error);
    }
}
// Function to extract data from the job list row
async function extractListData(row) {
    try {
        // Get job number first as it's the most critical
        const jobNumber = await row.getAttribute("data-jobnumber");
        if (!jobNumber) {
            console.error("No job number found in row");
            return null;
        }
        // Use a more resilient approach to get cell data
        const getCellText = async (selector) => {
            try {
                return await row.$eval(selector, (el) => el.textContent?.trim() || "");
            }
            catch (error) {
                console.warn(`Failed to get cell text for ${selector}:`, error);
                return "";
            }
        };
        const getCellAttribute = async (selector, attribute) => {
            try {
                return await row.$eval(selector, (el) => el.getAttribute(attribute) || "");
            }
            catch (error) {
                console.warn(`Failed to get cell attribute ${attribute} for ${selector}:`, error);
                return "";
            }
        };
        // Extract customer name properly - get only the text before the job tag container
        const customerName = await row
            .$eval("td:nth-child(2)", (td) => {
            // Get all text nodes that are direct children of the td
            const walker = document.createTreeWalker(td, NodeFilter.SHOW_TEXT, {
                acceptNode: (node) => {
                    // Only accept text nodes that are direct children of td
                    // and not inside the jobtag-container
                    const parent = node.parentElement;
                    if (!parent)
                        return NodeFilter.FILTER_REJECT;
                    // Reject if inside jobtag-container
                    if (parent.closest(".jobtag-container, .js-jobtag-container")) {
                        return NodeFilter.FILTER_REJECT;
                    }
                    // Accept if parent is the td itself or a direct child
                    if (parent === td || parent.parentElement === td) {
                        return NodeFilter.FILTER_ACCEPT;
                    }
                    return NodeFilter.FILTER_REJECT;
                },
            });
            let customerName = "";
            let node;
            while ((node = walker.nextNode())) {
                const text = node.textContent?.trim();
                if (text && text.length > 0) {
                    customerName += text + " ";
                }
            }
            return customerName.trim();
        })
            .catch(() => "");
        console.log(`üè¢ Extracted customer name: "${customerName}"`);
        // Extract job descriptions from job tag container
        const jobDescriptions = await row
            .$$eval(".jobtag-container .tag-text", (tagElements) => {
            return tagElements
                .map((tagEl) => {
                const text = tagEl.textContent?.trim() || "";
                // Find the parent span with data attributes
                const parentSpan = tagEl.closest("span[data-when-entered-utc]");
                const timestamp = parentSpan?.getAttribute("data-when-entered-utc") || "";
                // Extract author from tooltip if available
                const tooltip = parentSpan?.getAttribute("data-tooltip") || "";
                const authorMatch = tooltip.match(/from @(\w+)/);
                const author = authorMatch ? authorMatch[1] : undefined;
                return {
                    text,
                    timestamp,
                    author,
                };
            })
                .filter((desc) => desc.text.length > 0); // Filter out empty descriptions
        })
            .catch(() => []);
        console.log(`üìù Extracted ${jobDescriptions.length} job descriptions for job ${jobNumber}`);
        // Get other cell data with error handling and proper date validation
        const [description, status, orderNumber, dateInRaw, shipDateRaw] = await Promise.all([
            getCellText("td:nth-child(3)"),
            getCellText("td:nth-child(4) .cw--master-status-pill"),
            getCellText("td:nth-child(5)"),
            getCellAttribute("td:nth-child(6) .js-tz-aware", "data-tz-utc"),
            getCellAttribute("td:nth-child(7) .js-tz-aware", "data-tz-utc"),
        ]);
        // Additional debugging - get all cell contents to understand the structure
        const allCells = await row
            .$$eval("td", (cells) => {
            return cells.map((cell, index) => ({
                index: index + 1,
                textContent: cell.textContent?.trim() || "",
                innerHTML: cell.innerHTML?.substring(0, 100) + "..." || "",
            }));
        })
            .catch(() => []);
        console.log(`üîç All cells for job ${jobNumber}:`, JSON.stringify(allCells, null, 2));
        // Try fallback selectors for dates if primary ones fail
        let dateInFallback = "";
        let shipDateFallback = "";
        if (!dateInRaw) {
            dateInFallback = await getCellText("td:nth-child(6)").catch(() => "");
            console.log(`üîÑ Date In fallback text: "${dateInFallback}"`);
        }
        if (!shipDateRaw) {
            shipDateFallback = await getCellText("td:nth-child(7)").catch(() => "");
            console.log(`üîÑ Ship Date fallback text: "${shipDateFallback}"`);
        }
        // Debug extracted data
        console.log(`üîç Raw extracted data for job ${jobNumber}:`);
        console.log(`   Description: "${description}"`);
        console.log(`   Status: "${status}"`);
        console.log(`   Order Number: "${orderNumber}"`);
        console.log(`   Date In Raw: "${dateInRaw}"`);
        console.log(`   Ship Date Raw: "${shipDateRaw}"`);
        console.log(`   Date In Fallback: "${dateInFallback}"`);
        console.log(`   Ship Date Fallback: "${shipDateFallback}"`);
        // Clean the title by removing tag information and formatting properly
        const cleanTitle = (rawTitle) => {
            if (!rawTitle)
                return "";
            console.log(`üßπ Starting title cleanup for: "${rawTitle}"`);
            // First, normalize whitespace and remove newlines
            let cleanedTitle = rawTitle
                .replace(/\n/g, " ") // Replace newlines with spaces
                .replace(/\r/g, " ") // Replace carriage returns with spaces
                .replace(/\s+/g, " ") // Normalize multiple spaces to single space
                .trim();
            console.log(`üßπ After whitespace normalization: "${cleanedTitle}"`);
            // Remove various tag formats:
            // 1. Tag codes with numbers (like EM50, HW50, CR53, Bagging106)
            cleanedTitle = cleanedTitle.replace(/\b[A-Z]{2,8}\d+\b/g, "");
            // 2. Common tag words followed by numbers (like "Bagging106", "Misc53")
            cleanedTitle = cleanedTitle.replace(/\b(Bagging|Misc|Miscellaneous)\d+\b/gi, "");
            // 3. Remove standalone numbers that might be quantities
            cleanedTitle = cleanedTitle.replace(/\b\d{1,4}\b/g, "");
            // 4. Clean up any leftover patterns
            cleanedTitle = cleanedTitle
                .replace(/\s+/g, " ") // Normalize spaces again
                .trim();
            console.log(`üßπ After tag removal: "${cleanedTitle}"`);
            // Convert to proper case (Title Case) but preserve known acronyms
            const knownAcronyms = [
                "LLC",
                "INC",
                "USA",
                "US",
                "UK",
                "API",
                "GPS",
                "USB",
                "LED",
                "USB",
            ];
            cleanedTitle = cleanedTitle
                .toLowerCase()
                .split(" ")
                .map((word) => {
                if (word.length === 0)
                    return word;
                // Check if it's a known acronym
                const upperWord = word.toUpperCase();
                if (knownAcronyms.includes(upperWord)) {
                    return upperWord;
                }
                // Regular title case
                return word.charAt(0).toUpperCase() + word.slice(1);
            })
                .join(" ")
                .trim();
            console.log(`üßπ Final title result: "${cleanedTitle}"`);
            return cleanedTitle;
        };
        const cleanedTitle = cleanTitle(description);
        // Validate and format dates properly based on database schema
        const validateShipDate = (dateStr) => {
            if (!dateStr || dateStr.trim() === "") {
                console.log(`üìÖ Empty ship_date field, setting to null`);
                return null;
            }
            // Clean the date string - remove extra text and whitespace
            let cleanDateStr = dateStr.trim();
            // Extract date pattern (MM/DD/YYYY) from string that might contain extra text
            const dateMatch = cleanDateStr.match(/(\d{1,2}\/\d{1,2}\/\d{4})/);
            if (dateMatch) {
                cleanDateStr = dateMatch[1];
                console.log(`üìÖ Extracted clean date: "${cleanDateStr}" from "${dateStr}"`);
            }
            try {
                const date = new Date(cleanDateStr);
                if (isNaN(date.getTime())) {
                    console.warn(`üìÖ Invalid ship_date format: "${dateStr}", setting to null`);
                    return null;
                }
                return date.toISOString().split("T")[0]; // Return date only (YYYY-MM-DD)
            }
            catch (error) {
                console.warn(`üìÖ Ship date parsing error for "${dateStr}":`, error);
                return null;
            }
        };
        const validateCreatedAt = (dateStr) => {
            if (!dateStr || dateStr.trim() === "") {
                console.log(`üìÖ Empty created_at field, will use database default`);
                return undefined; // Omit field so database uses defaultNow()
            }
            // Clean the date string - remove extra text and whitespace
            let cleanDateStr = dateStr.trim();
            // Extract date pattern (MM/DD/YYYY) from string that might contain extra text
            const dateMatch = cleanDateStr.match(/(\d{1,2}\/\d{1,2}\/\d{4})/);
            if (dateMatch) {
                cleanDateStr = dateMatch[1];
                console.log(`üìÖ Extracted clean created date: "${cleanDateStr}" from "${dateStr}"`);
            }
            try {
                const date = new Date(cleanDateStr);
                if (isNaN(date.getTime())) {
                    console.warn(`üìÖ Invalid created_at format: "${dateStr}", will use database default`);
                    return undefined;
                }
                return date.toISOString();
            }
            catch (error) {
                console.warn(`üìÖ Created_at parsing error for "${dateStr}":`, error);
                return undefined;
            }
        };
        const shipDate = validateShipDate(shipDateRaw || shipDateFallback);
        const createdAt = validateCreatedAt(dateInRaw || dateInFallback);
        console.log(`üìÖ Processed dates - Created: ${createdAt || "database default"}, Ship: ${shipDate || "null"}`);
        // Clean the customer name to ensure it's properly formatted
        const cleanedCustomerName = cleanCustomerName(customerName);
        // Get tags with error handling
        let processCodes = [];
        try {
            await row.waitForSelector(".ew-badge.static", { timeout: 5000 });
            processCodes = await row.$$eval(".ew-badge.static", (badges) => {
                return badges.map((badge) => {
                    const code = badge.getAttribute("data-code")?.toUpperCase() || "";
                    const quantity = parseInt(badge.querySelector(".process-qty")?.textContent || "0");
                    return { code, quantity };
                });
            });
        }
        catch (e) {
            console.warn(`Timeout waiting for tags in job row ${jobNumber}. Proceeding without tags.`);
        }
        // Normalize tag codes
        const normalizedTags = processCodes.map((tag) => ({
            code: tag.code === "MISC" ? "MISC" : tag.code,
            quantity: tag.quantity,
        }));
        // Build the order object conditionally including created_at only if we have a valid value
        const orderData = {
            order_number: orderNumber,
            title: cleanedTitle,
            status: status,
            ship_date: shipDate,
        };
        // Only include created_at if we have a valid value
        if (createdAt !== undefined) {
            orderData.created_at = createdAt;
        }
        return {
            jobNumber,
            customer: { name: cleanedCustomerName },
            order: orderData,
            tags: normalizedTags,
            jobDescriptions: jobDescriptions,
        };
    }
    catch (error) {
        console.error("Error extracting list data:", error);
        return null;
    }
}
// Function to extract image data from job details page
async function extractImageData(page, jobNumber) {
    // Helper function to extract base path from URL
    const extractBasePath = (url) => {
        try {
            if (!url)
                return "";
            if (url.startsWith("/"))
                return url;
            const urlObj = new URL(url);
            return urlObj.pathname;
        }
        catch (error) {
            console.error("Error extracting base path:", error);
            return "";
        }
    };
    try {
        console.log(`üñºÔ∏è  Extracting images for job ${jobNumber}...`);
        // Wait for the page to be fully loaded
        await page.waitForLoadState("networkidle");
        // Find all image containers
        const imageContainers = await page.$$(".js-jobline-asset-image-container");
        console.log(`üîç Found ${imageContainers.length} image containers for job ${jobNumber}`);
        if (imageContainers.length === 0) {
            console.log(`‚ùå No image containers found for job ${jobNumber}`);
            return [];
        }
        const processedImages = [];
        // Process each container
        for (let i = 0; i < imageContainers.length; i++) {
            const container = imageContainers[i];
            console.log(`üîç Processing container ${i + 1}/${imageContainers.length}...`);
            try {
                // Get asset tag from container
                const assetTag = await container.getAttribute("data-asset-tag");
                console.log(`   üìù Asset tag: ${assetTag}`);
                if (!assetTag) {
                    console.log(`   ‚ö†Ô∏è No asset tag found for container ${i + 1}, skipping`);
                    continue;
                }
                // Check if container has images (many containers are empty)
                const img = await container.$("img[src]");
                const link = await container.$("a[href]");
                if (!img || !link) {
                    console.log(`   üì≠ Container ${assetTag} is empty (no images), skipping`);
                    continue;
                }
                // Extract URLs directly from DOM (no clicking needed!)
                const thumbnailUrl = await img.getAttribute("src");
                const highResUrl = await link.getAttribute("href");
                console.log(`   üñºÔ∏è  Thumbnail URL: ${thumbnailUrl?.substring(0, 80)}...`);
                console.log(`   üì∏ High-res URL: ${highResUrl?.substring(0, 80)}...`);
                // Validate that we have both URLs
                if (!thumbnailUrl || !highResUrl) {
                    console.log(`   ‚ö†Ô∏è Missing URLs for ${assetTag} - thumbnail: ${!!thumbnailUrl}, high-res: ${!!highResUrl}`);
                    continue;
                }
                // Validate URLs are proper blob storage URLs
                const isThumbnailValid = thumbnailUrl.includes("blob.core.windows.net") &&
                    (thumbnailUrl.includes("/thumbnails/") ||
                        thumbnailUrl.includes("_50."));
                const isHighResValid = highResUrl.includes("blob.core.windows.net") &&
                    !highResUrl.includes("/thumbnails/") &&
                    !highResUrl.includes("_50.");
                if (!isThumbnailValid) {
                    console.log(`   ‚ö†Ô∏è Invalid thumbnail URL for ${assetTag}: ${thumbnailUrl.substring(0, 80)}...`);
                }
                if (!isHighResValid) {
                    console.log(`   ‚ö†Ô∏è Invalid high-res URL for ${assetTag}: ${highResUrl.substring(0, 80)}...`);
                }
                // Store the image data (even if validation warnings occurred)
                processedImages.push({
                    asset_tag: assetTag,
                    thumbnail_url: thumbnailUrl,
                    high_res_url: highResUrl,
                    thumbnail_base_path: extractBasePath(thumbnailUrl),
                    high_res_base_path: extractBasePath(highResUrl),
                });
                console.log(`   ‚úÖ Successfully processed image for ${assetTag}`);
            }
            catch (error) {
                console.error(`   ‚ùå Error processing container ${i + 1}:`, error);
                continue;
            }
        }
        console.log(`‚úÖ Successfully processed ${processedImages.length} images for job ${jobNumber}`);
        // Summary of results
        const validThumbnails = processedImages.filter((img) => img.thumbnail_url.includes("blob.core.windows.net") &&
            (img.thumbnail_url.includes("/thumbnails/") ||
                img.thumbnail_url.includes("_50.")));
        const validHighRes = processedImages.filter((img) => img.high_res_url.includes("blob.core.windows.net") &&
            !img.high_res_url.includes("/thumbnails/") &&
            !img.high_res_url.includes("_50."));
        console.log(`üìä Image Quality Summary:`);
        console.log(`   ‚úÖ Valid thumbnails: ${validThumbnails.length}/${processedImages.length}`);
        console.log(`   ‚úÖ Valid high-res: ${validHighRes.length}/${processedImages.length}`);
        return processedImages;
    }
    catch (error) {
        console.error(`‚ùå Failed to extract images for job ${jobNumber}:`, error);
        return [];
    }
}
// Main function to extract job data
async function extractJobData(row, page, currentPageNumber) {
    try {
        // First get all the data from the list view BEFORE any navigation
        const listData = await extractListData(row);
        if (!listData) {
            console.error("Failed to extract list data");
            return null;
        }
        // Store the list data we need
        const { jobNumber } = listData;
        // Now that we have all list data, we can safely navigate
        const jobLink = await row.$(`a[href*="job.aspx?ID=${jobNumber}"]`);
        if (!jobLink) {
            console.error(`Could not find job link for job ${jobNumber}`);
            return {
                ...listData,
                order: {
                    ...listData.order,
                    images: [],
                },
            };
        }
        // Get the href before clicking
        const href = await jobLink.getAttribute("href");
        console.log(`üìÑ Navigating to job ${jobNumber} details via ${href}...`);
        // Navigate to job details page
        try {
            await page.goto(href, { waitUntil: "networkidle", timeout: 30000 });
            console.log("‚úÖ Job details page loaded successfully");
        }
        catch (navigationError) {
            console.error(`‚ùå Navigation failed for job ${jobNumber}:`, navigationError);
            return {
                ...listData,
                order: {
                    ...listData.order,
                    images: [],
                },
            };
        }
        // Extract image data
        let images;
        try {
            images = await extractImageData(page, jobNumber);
        }
        catch (imageError) {
            console.error(`‚ùå Image extraction failed for job ${jobNumber}:`, imageError);
            images = [];
        }
        // Navigate back to the correct page using pagination (not URL-based navigation)
        try {
            console.log(`üîô Returning to job list page ${currentPageNumber}...`);
            // First go back to the main job list
            await page.goto("https://intranet.decopress.com/JobStatusList/JobStatusList.aspx?from=menu", { waitUntil: "networkidle", timeout: 30000 });
            console.log(`üìç Back to main job list, now navigating to page ${currentPageNumber}`);
            // If we need to go to a page other than 1, click the pagination
            if (currentPageNumber > 1) {
                // Wait for initial page to load
                await waitForJobListSync(page);
                // Click the pagination button for our target page
                console.log(`üîò Clicking pagination for page ${currentPageNumber}...`);
                await page.click(`.pagination li.page-item[data-lp="${currentPageNumber}"] a`);
                // Wait for the page to load and sync
                await waitForJobListSync(page);
                // Verify we're on the correct page
                try {
                    const activePageElement = await page.$(".pagination li.page-item.active[data-lp]");
                    if (activePageElement) {
                        const activePage = await activePageElement.getAttribute("data-lp");
                        console.log(`‚úÖ Confirmed back on page ${activePage}`);
                    }
                }
                catch (verifyError) {
                    console.warn("‚ö†Ô∏è Could not verify current page:", verifyError);
                }
            }
            else {
                // We're already on page 1, just sync
                await waitForJobListSync(page);
                console.log("‚úÖ Back on page 1");
            }
            console.log("‚úÖ Successfully returned to job list");
        }
        catch (backError) {
            console.error(`‚ùå Failed to return to job list page ${currentPageNumber} after job ${jobNumber}:`, backError);
            console.log("‚ö†Ô∏è Will continue without proper navigation back");
        }
        // Combine the data
        return {
            ...listData,
            order: {
                ...listData.order,
                images,
            },
        };
    }
    catch (error) {
        console.error("Error extracting job data:", error);
        return null;
    }
}
// Function to scrape all jobs from the list
async function scrapeJobs(page, currentPageNumber = 1) {
    console.log(`Scraping jobs on page ${currentPageNumber}...`);
    try {
        // Wait for the jobs table to be visible
        await page.waitForSelector("#jobStatusListResults");
        const jobs = [];
        const failedJobs = [];
        const skippedJobs = [];
        let processedCount = 0;
        // Get organization name for job existence checks
        const envOrgName = process.env.ORGANIZATION_NAME || "DecoPress";
        // Add space programmatically if needed: "DecoPress" -> "Deco Press"
        const orgName = envOrgName === "DecoPress" ? "Deco Press" : envOrgName;
        while (true) {
            // Get currently available job rows on this page (dynamic approach)
            const currentJobRows = await page.$$eval("#jobStatusListResults tr.js-jobstatus-row", (rows) => {
                return rows
                    .map((row, index) => {
                    const jobNumber = row.getAttribute("data-jobnumber");
                    const orderNumber = row.querySelector("td:nth-child(5)")?.textContent?.trim() || "";
                    const link = row
                        .querySelector(`a[href*="job.aspx?ID=${jobNumber}"]`)
                        ?.getAttribute("href");
                    return {
                        jobNumber,
                        orderNumber,
                        link,
                        index,
                    };
                })
                    .filter((item) => item.jobNumber !== null && item.link !== null);
            });
            if (currentJobRows.length === 0) {
                console.log("No more job rows found on current page");
                break;
            }
            // Find the next unprocessed job (we process them in order)
            const nextJob = currentJobRows[processedCount];
            if (!nextJob) {
                console.log("All jobs on current page have been processed");
                break;
            }
            const { jobNumber, orderNumber, link } = nextJob;
            processedCount++;
            try {
                console.log(`üîÑ Processing job ${jobNumber} (${processedCount}/${currentJobRows.length})...`);
                // Check if this job already exists in the database with images
                console.log(`üîç Checking if job ${jobNumber} (order: ${orderNumber}) already exists...`);
                const jobCheck = await checkJobExists(orgName, orderNumber, true);
                if (jobCheck.exists) {
                    if (jobCheck.hasImages) {
                        console.log(`‚è≠Ô∏è  Skipping job ${jobNumber} - already exists with images`);
                        skippedJobs.push(jobNumber);
                        continue;
                    }
                    else {
                        console.log(`üîÑ Job ${jobNumber} exists but missing images - will update`);
                    }
                }
                else {
                    console.log(`üÜï Job ${jobNumber} is new - will process`);
                }
                // Extract list data with row-based approach for better reliability
                const row = await page.$(`tr[data-jobnumber="${jobNumber}"]`);
                if (!row) {
                    console.error(`‚ùå Could not find row for job ${jobNumber}`);
                    failedJobs.push(jobNumber);
                    continue;
                }
                // Use extractJobData to handle navigation and image extraction
                const jobData = await extractJobData(row, page, currentPageNumber);
                if (!jobData) {
                    console.error(`‚ùå Failed to extract job data for job ${jobNumber}`);
                    failedJobs.push(jobNumber);
                    continue;
                }
                jobs.push(jobData);
                console.log(`‚úÖ Successfully processed job ${jobNumber}`);
            }
            catch (error) {
                console.error(`‚ùå Error processing job ${jobNumber}:`, error);
                failedJobs.push(jobNumber);
                // Try to recover page state for next job
                try {
                    console.log(`üîÑ Attempting to recover to page ${currentPageNumber}...`);
                    await navigateToPage(page, currentPageNumber);
                    await waitForJobListSync(page);
                    console.log(`‚úÖ Recovered page state for page ${currentPageNumber}`);
                    // Continue with next job instead of restarting
                }
                catch (recoveryError) {
                    console.error(`‚ùå Failed to recover page state:`, recoveryError);
                    // Continue anyway - might still work
                }
                continue;
            }
        }
        console.log(`\nüìä Page ${currentPageNumber} Scraping Summary:`);
        console.log(`‚úÖ Successfully processed: ${jobs.length} jobs`);
        console.log(`‚è≠Ô∏è  Skipped (already exist): ${skippedJobs.length} jobs`);
        console.log(`‚ùå Failed to process: ${failedJobs.length} jobs`);
        if (skippedJobs.length > 0) {
            console.log(`Skipped jobs: ${skippedJobs.join(", ")}`);
        }
        if (failedJobs.length > 0) {
            console.log(`Failed jobs: ${failedJobs.join(", ")}`);
        }
        return jobs;
    }
    catch (error) {
        console.error(`‚ùå Critical error in scrapeJobs for page ${currentPageNumber}:`, error);
        throw error;
    }
}
// Helper function to wait for job list page synchronization
async function waitForJobListSync(page) {
    try {
        // Wait for multiple conditions to ensure the page is fully loaded
        await Promise.all([
            // Wait for network to be idle
            page.waitForLoadState("networkidle"),
            // Wait for the table to be populated
            page.waitForSelector("#jobStatusListResults tr.js-jobstatus-row", {
                timeout: 15000,
                state: "attached",
            }),
            // Wait for any loading indicators to disappear
            page
                .waitForSelector(".loading-indicator", {
                state: "hidden",
                timeout: 5000,
            })
                .catch(() => { }), // Don't fail if loading indicator doesn't exist
        ]);
        // Additional wait to ensure JavaScript has finished processing and rows are interactive
        await page.waitForFunction(() => {
            const rows = document.querySelectorAll("#jobStatusListResults tr.js-jobstatus-row");
            return (rows.length > 0 &&
                Array.from(rows).every((row) => row.offsetHeight > 0));
        }, { timeout: 10000 });
        // Additional small delay to ensure DOM is stable
        await page.waitForTimeout(1000);
        console.log("‚úÖ Job list page synchronized");
    }
    catch (error) {
        console.warn("‚ö†Ô∏è Job list synchronization had issues:", error);
    }
}
// Helper function to navigate to a specific page
async function navigateToPage(page, pageNumber) {
    try {
        if (pageNumber === 1) {
            // Navigate to the main job list page
            await page.goto("https://intranet.decopress.com/JobStatusList/JobStatusList.aspx?from=menu", { waitUntil: "networkidle", timeout: 30000 });
        }
        else {
            // First go to page 1, then navigate to the desired page
            await page.goto("https://intranet.decopress.com/JobStatusList/JobStatusList.aspx?from=menu", { waitUntil: "networkidle", timeout: 30000 });
            await waitForJobListSync(page);
            // Click the pagination link for the desired page
            await page.click(`.pagination li.page-item[data-lp="${pageNumber}"] a`);
        }
        // Ensure the page is fully synchronized
        await waitForJobListSync(page);
    }
    catch (error) {
        console.error(`Failed to navigate to page ${pageNumber}:`, error);
        throw error;
    }
}
// Scrape all jobs across paginated pages
async function scrapeAllJobs(page) {
    let allJobs = [];
    try {
        console.log("üîç Checking pagination...");
        // Get total number of pages from pagination
        const totalPages = await page
            .$$eval(".pagination li.page-item:not(.prev):not(.next)", (items) => items.length)
            .catch(() => {
            console.log("No pagination found, assuming single page");
            return 1;
        });
        console.log(`üìÑ Found ${totalPages} pages to scrape`);
        for (let i = 1; i <= totalPages; i++) {
            try {
                console.log(`\nüìñ Processing page ${i}/${totalPages}...`);
                if (i > 1) {
                    console.log(`üîÑ Navigating to page ${i}...`);
                    // Click the pagination link for page i
                    try {
                        await page.click(`.pagination li.page-item[data-lp="${i}"] a`);
                        console.log(`‚úÖ Clicked pagination link for page ${i}`);
                    }
                    catch (clickError) {
                        console.error(`‚ùå Failed to click pagination for page ${i}:`, clickError);
                        continue;
                    }
                    // Use our robust synchronization function
                    console.log(`‚è≥ Waiting for page ${i} to load and synchronize...`);
                    await waitForJobListSync(page);
                    // Additional verification that we're on the correct page
                    try {
                        const currentPageElement = await page.$(".pagination li.page-item.active[data-lp]");
                        if (currentPageElement) {
                            const currentPageNum = await currentPageElement.getAttribute("data-lp");
                            console.log(`‚úÖ Confirmed on page ${currentPageNum}`);
                            if (currentPageNum !== i.toString()) {
                                console.warn(`‚ö†Ô∏è Expected page ${i} but on page ${currentPageNum}`);
                            }
                        }
                    }
                    catch (pageCheckError) {
                        console.warn("‚ö†Ô∏è Could not verify current page:", pageCheckError);
                    }
                    // Extra delay to ensure page is fully stable after pagination
                    await page.waitForTimeout(2000);
                    console.log(`‚úÖ Page ${i} is ready for scraping`);
                }
                // Scrape jobs on the current page
                console.log(`üöÄ Starting to scrape jobs on page ${i}...`);
                const jobs = await scrapeJobs(page, i);
                console.log(`‚úÖ Page ${i} complete: ${jobs.length} jobs scraped`);
                allJobs = allJobs.concat(jobs);
                // Log cumulative progress
                console.log(`üìä Total progress: ${allJobs.length} jobs from ${i}/${totalPages} pages`);
            }
            catch (error) {
                console.error(`‚ùå Error processing page ${i}:`, error);
                // Try to recover by navigating back to the job list
                try {
                    console.log(`üîÑ Attempting to recover page state...`);
                    await page.goto("https://intranet.decopress.com/JobStatusList/JobStatusList.aspx?from=menu", { waitUntil: "networkidle", timeout: 30000 });
                    await waitForJobListSync(page);
                    console.log(`‚úÖ Recovered page state, continuing with next page`);
                }
                catch (recoveryError) {
                    console.error(`‚ùå Failed to recover from page ${i} error:`, recoveryError);
                }
                // Continue with next page instead of failing completely
                continue;
            }
        }
        console.log(`\nüéâ Pagination complete! Total jobs scraped: ${allJobs.length}`);
    }
    catch (error) {
        console.error("‚ùå Critical error in scrapeAllJobs:", error);
    }
    return allJobs;
}
// Main function to run the scraper
async function run() {
    let browser = null;
    try {
        // Load saved credentials
        const credentials = await loadCredentials();
        // Handle user authentication
        let username, password, useStoredAuth = false;
        if (credentials.accounts && credentials.accounts.length > 0) {
            console.log("Saved accounts:");
            credentials.accounts.forEach((account, index) => {
                console.log(`${index + 1}. ${account.username}`);
            });
            console.log(`${credentials.accounts.length + 1}. Use a new account`);
            const choice = await promptUser("Select an account (number) or press Enter for last used: ");
            if (choice === "") {
                // Use last used account
                const lastUsed = credentials.accounts.find((a) => a.isLastUsed) ||
                    credentials.accounts[0];
                username = lastUsed.username;
                password = lastUsed.password;
                useStoredAuth = true;
                console.log(`Using account: ${username}`);
            }
            else {
                const choiceNum = parseInt(choice);
                if (choiceNum > 0 && choiceNum <= credentials.accounts.length) {
                    username = credentials.accounts[choiceNum - 1].username;
                    password = credentials.accounts[choiceNum - 1].password;
                    useStoredAuth = true;
                    console.log(`Using account: ${username}`);
                }
                else {
                    // New account flow
                    username = await promptUser("Enter username: ");
                    password = await promptUser("Enter password: ");
                    const saveAccount = await promptUser("Save this account for future use? (y/n): ");
                    if (saveAccount.toLowerCase() === "y") {
                        // Update all accounts to not be last used
                        credentials.accounts.forEach((account) => (account.isLastUsed = false));
                        // Add new account
                        credentials.accounts.push({
                            username,
                            password,
                            isLastUsed: true,
                        });
                        await saveCredentials(credentials);
                        console.log("Account saved!");
                    }
                }
            }
            // Update last used account
            if (useStoredAuth) {
                credentials.accounts.forEach((account) => {
                    account.isLastUsed = account.username === username;
                });
                await saveCredentials(credentials);
            }
        }
        else {
            // No saved accounts
            username = await promptUser("Enter username: ");
            password = await promptUser("Enter password: ");
            const saveAccount = await promptUser("Save this account for future use? (y/n): ");
            if (saveAccount.toLowerCase() === "y") {
                credentials.accounts = [
                    {
                        username,
                        password,
                        isLastUsed: true,
                    },
                ];
                await saveCredentials(credentials);
                console.log("Account saved!");
            }
        }
        // Launch browser with increased timeouts
        browser = await chromium.launch({
            headless: false,
            slowMo: 100,
            timeout: 60000, // 60 second timeout
        });
        // Use a persistent context to maintain cookies between runs
        const context = await browser.newContext({
            storageState: fs.existsSync(CONFIG_DIR + "/storage.json")
                ? CONFIG_DIR + "/storage.json"
                : undefined,
            viewport: { width: 1280, height: 800 },
            userAgent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        });
        const page = await context.newPage();
        // Set longer timeouts for navigation and waiting
        page.setDefaultTimeout(60000); // 60 seconds timeout
        page.setDefaultNavigationTimeout(60000);
        // üîê 1. LOGIN TO OMS
        console.log("Navigating to login page...");
        await page.goto("https://intranet.decopress.com/", {
            waitUntil: "networkidle",
        });
        // Check if login form exists (if not, we're already logged in)
        const loginFormExists = await page.evaluate(() => {
            return !!document.querySelector("#txt_Username");
        });
        if (loginFormExists) {
            console.log("Logging in...");
            await page.fill("#txt_Username", username);
            await page.fill("#txt_Password", password);
            // Find and click the login button
            const loginButtonSelector = [
                'input[type="button"]',
                'input[type="submit"]',
                'button[type="submit"]',
                "#login-button",
            ];
            for (const selector of loginButtonSelector) {
                const button = await page.$(selector);
                if (button) {
                    await button.click();
                    console.log(`Clicked login button using selector: ${selector}`);
                    break;
                }
            }
            console.log("Login successful");
        }
        else {
            console.log("Already logged in");
        }
        // Save storage state for future runs
        await context.storageState({ path: CONFIG_DIR + "/storage.json" });
        // üìÑ 2. NAVIGATE TO JOB LIST
        console.log("Navigating to job list...");
        await page.goto("https://intranet.decopress.com/JobStatusList/JobStatusList.aspx?from=menu", {
            waitUntil: "networkidle",
            timeout: 30000,
        });
        // Wait for both the table and its contents to be fully loaded
        await Promise.all([
            // Wait for network to be idle
            page.waitForLoadState("networkidle"),
            // Wait for the table to be populated
            page.waitForSelector("#jobStatusListResults tr.js-jobstatus-row", {
                timeout: 20000,
                state: "attached",
            }),
            // Wait for any loading indicators to disappear
            page
                .waitForSelector(".loading-indicator", {
                state: "hidden",
                timeout: 5000,
            })
                .catch(() => { }),
        ]);
        // Additional wait to ensure JavaScript has finished processing
        await page.waitForFunction(() => {
            const rows = document.querySelectorAll("#jobStatusListResults tr.js-jobstatus-row");
            return (rows.length > 0 &&
                Array.from(rows).every((row) => row.offsetHeight > 0));
        }, { timeout: 5000 });
        console.log("Job rows are visible and fully loaded");
        // Debug: Save screenshot and HTML
        await page.screenshot({ path: "debug_jobs_page.png" });
        const html = await page.content();
        fs.writeFileSync("debug_jobs_page.html", html);
        console.log("Saved debug_jobs_page.png and debug_jobs_page.html");
        // Instead of scraping just one page, scrape all pages
        const jobs = await scrapeAllJobs(page);
        console.log(`Scraped ${jobs.length} jobs (all pages)`);
        // Save to database
        const envOrgName = process.env.ORGANIZATION_NAME || "DecoPress";
        // Add space programmatically if needed: "DecoPress" -> "Deco Press"
        const orgName = envOrgName === "DecoPress" ? "Deco Press" : envOrgName;
        const result = await saveScrapedJobs(orgName, jobs);
        console.log("Database save results:");
        console.log(`Successfully saved: ${result.success.length} jobs`);
        if (result.errors.length > 0) {
            console.log(`Failed to save: ${result.errors.length} jobs`);
            // Save errors to a file for review
            fs.writeFileSync("scrape_errors.json", JSON.stringify(result.errors, null, 2));
        }
    }
    catch (error) {
        console.error("Error during scraping:", error);
    }
    finally {
        if (browser) {
            try {
                await browser.close();
            }
            catch (error) {
                console.error("Error closing browser:", error);
            }
        }
    }
}
run();
export async function scrapeOrders() {
    const browser = await chromium.launch({
        headless: true,
    });
    try {
        const page = await browser.newPage();
        await page.goto("https://app.decopress.com/orders");
        // Wait for the orders table to load
        await page.waitForSelector(".orders-table");
        // Get all job rows
        const jobRows = await page.$$(".orders-table tr[data-jobnumber]");
        const jobs = [];
        for (const row of jobRows) {
            const jobData = await extractJobData(row, page, 1);
            if (jobData) {
                jobs.push(jobData);
            }
        }
        return jobs;
    }
    catch (error) {
        console.error("Error scraping orders:", error);
        throw error;
    }
    finally {
        await browser.close();
    }
}
